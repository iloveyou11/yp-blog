---
title: 机器学习40讲-jk时间
date: 2020-04-01
categories: AI
author: yangpei
tags:
  - 机器学习
comments: true
cover_picture: /images/banner.jpg
---

介绍机器学习基本知识点

<!-- more -->

本文均来自极客时间《机器学习40讲》

### 01 | 频率视角下的机器学习
“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着概率的频率学派（Frequentist）和贝叶斯学派（Bayesian）。

归根到底，频率学派口中的概率表示的是事件发生频率的极限值，它只有在无限次的独立重复试验之下才有绝对的精确意义。在频率学派眼中，当重复试验的次数趋近于无穷大时，事件发生的频率会收敛到真实的概率之上。这种观点背后暗含了一个前提，那就是概率是一个确定的值，并不会受单次观察结果的影响。

基于以上的逻辑，把根据频率计算概率的过程反转过来，就是频率统计估计参数的过程。频率统计理论的核心在于认定待估计的参数是固定不变的常量，讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量，每个数据都是参数支配下一次独立重复试验的结果。由于参数本身是确定的，那频率的波动就并非来源于参数本身的不确定性，而是由有限次观察造成的干扰而导致。

**这可以从两个角度来解释：一方面，根据这些不精确的数据就可以对未知参数的精确取值做出有效的推断；另一方面，数据中包含的只是关于参数不完全的信息，所以从样本估计整体就必然会产生误差。**

统计学的核⼼任务之一是根据从总体中抽取出的样本，也就是数据来估计未知的总体参数。参数的最优估计可以通过样本数据的分布，也就是采样分布（sampling distribution）来求解，由于频率统计将数据看作随机变量，所以计算采样分布是没有问题的。确定采样分布之后，参数估计可以等效成一个最优化的问题，而频率统计最常使用的最优化方法，就是**最大似然估计（maximum likelihood estimation）**。

**总结起来，频率主义解决统计问题的基本思路如下：参数是确定的，数据是随机的，利用随机的数据推断确定的参数，得到的结果也是随机的。**

**总结：**
频率学派对概率、统计学和机器学习的认识方式：
- 频率学派认为概率是随机事件发生频率的极限值；
- 频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；
- 频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；
- 频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。

### 02 | 贝叶斯视角下的机器学习
频率学派存在的问题：对于所有的“一锤子买卖”，也就是不包含随机变量的事件来说，频率学派对概率的解读都是不成立的。如不可能进行重复多次的实验。

为了解决频率主义的问题，贝叶斯学派给出了一种更加通用的概率定义：概率表示的是客观上事件的可信程度（degree of belief），也可以说成是主观上主体对事件的信任程度，它是建立在对事件的已有知识基础上的。比方说，当一个球迷提出“明天皇家马德里战胜拉斯帕尔马斯的概率是 86%”的时候，可以理解成他对皇马获胜有 86% 的把握程度，要是买球的话自然就会在独胜上下出重注。除了对概率的置信度解释之外，贝叶斯学派中的另一个核心内容是贝叶斯定理（Bayes' theorem），用来解决“逆向概率问题”（inverse probability problem）。逆向概率和前向概率是对应的：假定数据由一个生成模型给出，前向概率是在已知生成过程的前提下来计算数据的概率分布和数字特征，逆向概率则是在已知数据的前提下反过来计算生成过程的未知特性。贝叶斯定理的数学表达式可以写成`P(A|B)=P(A|B)*P(B)/P(A)`。

贝叶斯定理同样可以从贝叶斯概率的角度加以解读：所谓先验概率是指根据以往经验和分析得到的概率，可以视为假设 H 初始的可信程度；与假设 H 相关的数据 D 会作为证据出现，将数据纳入考虑范围后，假设 H 的可信程度要么会增强要么会削弱。但不管增强还是削弱，得到的结果都是经过数据验证的假设的可信程度，这就是后验概率。贝叶斯定理的意义正是在于**将先验概率和后验概率关联起来**，刻画了数据对于知识和信念的影响。

将贝叶斯定理应用到统计推断中，就是贝叶斯主义的统计学。频率统计理论的核⼼在于认定待估计的参数是固定不变的常量，⽽⽤来估计的数据是随机的变量。贝叶斯统计则恰恰相反：它将待估计的参数视为随机变量，用来估计的数据反过来是确定的常数，讨论观测数据的概率分布才是没有意义的。贝叶斯统计的任务就是根据这些确定的观测数据反过来推断未知参数的概率分布。

**相对于频率主义的最大似然估计，贝叶斯主义在参数估计中倾向于使后验概率最大化，使用最大后验概率估计（maximum a posteriori estimation）。**

最大后验估计则是将频率学派中“参数”和“数据”的角色做了个调换：参数本身是随机变量（服从先验分布），有许多可能的取值，而不同取值生成这一组观测数据（服从似然分布）也是不同的。因而最大后验概率推断的过程就是结合参数自身的分布特性，找到最可能产生观测数据的那个参数的过程。贝叶斯定理告诉我们，后验概率正比于先验概率和似然概率的乘积，这意味着后验概率实质上就是用先验概率对似然概率做了个加权处理。频率主义将参数看成常量，那么似然概率就足以描述参数和数据之间的关系。

既然贝叶斯主义能够提供更加完整的信息，为什么迟迟没有取代频率主义成为主流呢？这就不得不说**贝叶斯方法的缺点**了：一是`对未知变量的积分运算会导致极高的计算复杂度`（computation complexity）；二是`对先验分布的设定（prior specification）包含一定的主观性`，因而一直不招老派的统计学家待见。正是这两个原因限制了贝叶斯方法的广泛应用。

**总结：**
贝叶斯学派对概率、统计学和机器学习的认识方式：
- 贝叶斯学派认为概率是事件的可信程度或主体对事件的信任程度；
- 贝叶斯学派执行参数估计时，视参数为随机变量，视数据为确定取值；
- 贝叶斯学派主要使用最大后验概率法，让参数在先验信息和给定数据下的后验概率最大化；
- 贝叶斯学派对应机器学习中的概率图模型，可以在模型预测和选择中提供更加完整的信息。

### 03 | 学什么与怎么学
机器学习能够解决的问题必然会包含某些显式或者隐式的模式，没有模式的问题就不能通过机器学习解决。完全随机的问题是不可能被求解，也不可能被学习的，就像我们永远也没法预测示波器下一时刻的本底噪声一样。

是不是有潜在模式的问题都能够被机器所学习呢？也不尽然。流体力学的研究之中有不少复杂困难的问题，但机器学习也没有成为这个学科的主流方法，这意味着机器学习并不适用于易编程问题的解释。一个具有解析解的问题是完全不需要机器学习的。即使一个一次方程组中有一万个方程，每个方程中又有一万个未知数，这个看似复杂的问题本质上也无非就是个矩阵求逆，只是矩阵的规模比较大而已。如果将机器学习运用到这种问题上，那就是杀鸡用牛刀了。

退一步讲，即使问题本身没有解析解，要是能够通过数值计算的方法解决，而不涉及明显的优化过程的话，也无需机器学习的使用。在流体力学中，仿真是最常用的研究方法，大量的参数与繁冗的边界条件给计算带来了超高的复杂度。但在这样的问题中，机器学习即使被应用，可能也不会发挥出良好的效果，因为这在本质上依然是对等式方程的求解。就像“能用钱解决的问题都不是问题“一样，能用纯计算解决的问题也不是（需要先进方法的）问题。

总结起来，什么样的问题才能通过机器学习来解决呢？
- 首先，问题不能是完全随机的，需要具备一定的模式；
- 其次，问题本身不能通过纯计算的方法解决；
- 再次，有大量的数据可供使用。

如果训练数据中的每组输入都有其对应的输出结果，这类学习任务就是**监督学习**（supervised learning），对没有输出的数据进行学习则是**无监督学习**（unsupervised learning）。监督学习具有更好的预测精度，无监督学习则可以发现数据中隐含的结构特性，起到的也是分类的作用，只不过没有给每个类别赋予标签而已。无监督学习可以用于对数据进行聚类或者密度估计，也可以完成异常检测这类监督学习中的预处理操作。直观地看，监督学习适用于预测任务，无监督学习适用于描述任务。

**总结：**
机器学习所解决的问题特点，以及学习中使用的不同策略，其要点如下：
- 机器学习适用于解决蕴含潜在规律的问题；
- 纯算数问题无需使用机器学习；
- 机器学习需要大量数据来发现潜在规律；
- 从输入空间、输出空间、数据标签、学习策略等角度可以对机器学习进行分类。

**机器学习（machine learning）、模式识别（pattern recognition）、数据挖掘（data mining）、人工智能（artificial intelligence）的区别：**

<img width="40%" src="https://i.loli.net/2020/04/01/op2KCRwBgEUVLPi.jpg" alt="概念关系" />

`机器学习`是方法，`优化(optimization)和统计(statistics)`是其最重要得两项支撑技术。
`人工智能、模式识别、数据挖掘`，这三个是应用层面的概念，他们的概念互有交叠，产生背景和发展历史有所不同，但使用的工具又是相通的：
- 人工智能是六十年前达特茅斯会议提出的问题，最初的目标在于让机器解决听、看、理解、思考等人类智能行为问题。人工智能的假想敌——人类，恰恰由于多年的进化，在这些问题上能力非常强，所以人工智能从诞生那一天起就面临着巨大的挑战，三起三落才有所突破。
- 数据挖掘更多地是解决生产、金融、互联网等领域高维数据的缄默与规律发现，在最近几年人工智能概念的外延被大大拓展以后，这些面向高维数据的问题也被称为“超人工智能”问题。另外一个不同点，人工智能往往倾向于机器决策的“自动化(Automation)”方法论，而数据挖掘最初倾向于辅助人类决策的“洞察(insight)”方法论。不过今天来看，只有机器自动决策才是王道。
- 模式识别是早年间自动化领域提出的一个应用概念，相当于机器学习中的分类、聚类等概念的具体应用，由于场景适用面较窄，目前多为人工智能这个更宽泛的概念所替代了。

### 04 | 计算学习理论
**总结：**
这是评估机器学习的理论基础，也是机器学习理论研究的主要对象，其要点如下：
- Hoeffding 不等式描述了训练误差和泛化误差之间的近似关系；
- PAC 学习理论的核心在于学习出来的模型会以较大概率接近于最优模型；
- 假设空间的 VC 维是对无限假设空间复杂度的度量，体现了复杂性和性能的折中；
- Rademacher 复杂度是结合了先验信息的对函数空间复杂度的度量。

### 05 | 模型的分类方式
#### 参数模型和非参数模型
大多数情况下，机器学习的任务是求解输入输出单独或者共同符合的概率分布，或者拟合输入输出之间的数量关系。从数据的角度看，如果待求解的概率分布或者数量关系可以用一组有限且固定数目的参数完全刻画，求出的模型就是**参数模型**（parametric model）；反过来，不满足这个条件的模型就是**非参数模型**（non-parametric model）。

参数模型的优点在于只用少量参数就完整地描述出数据的概率特性，参数集中的每个参数都具有明确的统计意义。你可以回忆一下常用的典型概率分布，离散变量的二项分布`B(n,p) `只包含两个参数，分别代表独立重复试验的次数和每次试验中事件发生的概率；连续变量的正态分布 `N(μ,σ) `也是只包含两个参数，分别代表着随机变量的均值和方差。所以在参数模型的学习中，算法的任务就是求出这些决定概率特性的参数，只要参数确定了，数据的统计分布也就确定了，即使未知的数据无穷无尽，我们也可以通过几个简单的参数来确定它们的性质。

先验知识会假定数据满足特定的先验分布，学习的过程就是利用训练数据估计未知参数的过程，一旦得出未知参数的估计结果，训练数据就完成了它的历史使命，因为这些估计出来的参数就是训练数据的浓缩。在这个过程中，先验知识确定了假设空间的取值范围，学习算法（比如最大似然估计或是最大后验概率估计）则在给定的范围内求解最优化问题。

当对所要学习的问题知之甚少的时候，不懂装懂地搞些先验分布往数据上生搬硬套就不是合理的选择，最好的办法反而是避免对潜在模型做出过多的假设。这类不使用先验信息，完全依赖数据进行学习得到的模型就是非参数模型。

需要注意的是，“非参数模型”不是“无参数模型”，恰恰相反，`非参数模型意味着模型参数的数目是不固定的，并且极有可能是无穷大，这决定了非参数模型不可能像参数模型那样用固定且有限数目的参数来完全刻画。`在非参数模型中不存在关于数据潜在模式和结构化特性的任何假设，数据的所有统计特性都来源于数据本身，一切都是“所见即所得”。和参数相比，非参数模型的时空复杂度都会比参数模型大得多。但可以证明的是，当训练数据趋于无穷多时，非参数模型可以逼近任意复杂的真实模型，这给其实用性添加了一枚重量级的筹码。

❶ 参数模型
“新闻总是抄袭历史，模式在深处等待发掘。“
当我们对问题有认知，有了「定性」的判断，然后我们便可以用「定量」的方式将它们刻画出来。所谓“参数模型”。
- 优点：简单，只需付出较小的计算代价就可以从假设空间中习得一个较好的模型
- 缺点：其可用性却严重依赖于先验知识的可信度，但若先验分布错误，则无法学出好的结果。

❷ 非参数模型
“知之为知之，不知为不知，是知也。”
当我们对问题知之甚少，最好的办法反而是避免对潜在模型做出过多的假设，所谓“非参数模型。”
- 优点：当训练数据趋于无穷多时，非参数模型可以逼近任意复杂的真实模型。
- 缺点：和参数相比，非参数模型的时空复杂度都会比参数模型大得多。

#### 数据模型和算法模型

如果说参数模型与非参数模型的核心区别在于数据分布特征的整体性与局部性，那么数据模型和算法模型之间的矛盾就是模型的可解释性与精确性的矛盾，这可以通过两种模型的典型代表来解释。相比于参数对数据分布的刻画，这种分类方式更加侧重于模型对数据的拟合能力和预测能力。

数据模型最典型的方法就是线性回归，也就是将输出结果表示为输入特征的线性加权组合，算法通过训练数据来学习权重系数。线性回归的含义明确而清晰的含义：输入数据每个单位的变化对输出都会产生同步的影响，影响的程度取决于这个特征的权重系数，不同特征对结果的贡献一目了然。

❹ 数据模型
代表：线性回归
- 优点：可解释性强
- 缺点：简单模型有时不能充分体现出复杂作用机制

❺ 算法模型
代表：随机森林
- 优点：可描绘复杂的数据，精确度高
- 缺点：可解释性弱

#### 生成模型和判别模型
生成模型（generative model）学习的对象是输入 x 和输出 y 的联合分布 p(x,y)，判别模型学习的则是已知输入 x 的条件下，输出 y 的条件分布 p(y|x)。两个分布可以通过贝叶斯定理建立联系。

生成模型和判别模型的区别可以这样来理解：假如我被分配了一个任务，要判断一个陌生人说的是什么语言。如果用生成模型来解决的话，我就需要把这个老外可能说的所有语言都学会，再根据他的话来判定语言的种类。但可能等我学完这些语言时，这个陌生人都说不出话了。可是用判别模型就简单多了，我只需要掌握不同语言的区别就足够了。即使不会西班牙语或者德语的任何一个单词，单凭语感也可以区分出这两种语言，这就是判别模型的优势。

。一般来说，生成模型的求解更加复杂，当数据量趋于无穷大时，渐进条件下的精确性也更差，但其收敛的速度更快，在较少数据的训练后就可以收敛到错误的下界。相比之下，判别模型的形式更加简单，在分类问题上的表现也更出色，却不能提供关于数据生成机制的信息。有些情况下，生成模型和判别模型会成对出现。例如在分类问题中，朴素贝叶斯和逻辑回归就是一对生成 - 判别分类器。

❻ 生成模型 vs 判别模型：联合分布 vs 条件分布
生成模型（generative model）学习的对象是输入 x 和输出 y 的联合分布 p(x,y)
判别模型学习的则是已知输入 x 的条件下，输出 y 的条件分布 p(y|x)
区分的例子：以判断某种语言是什么？前者输出学完所有语言。后者是学会不同语言的区别。

**举例：**
- 线性回归是典型的参数模型，所有数据都用一组线性系数去拟合。由线性回归衍生出来的逻辑回归也是参数模型。
- 决策树是典型的非参模型，整个特征空间被分成若干块，相似的输入才会有相似的输出。
- 神经网络算是半参数模型，如果层数和神经元数都固定了就是参数模型，但在深度学习里做了dropout，就不知道哪些层的哪些神经元被激活，这时就是非参数了。
- 生成模型是对数据的生成机制进行建模，也就是求解x,y共同满足的分布。朴素贝叶斯是生成模型，它可以计算出p(y)和p(x|y)，进而计算p(x, y)。这个过程就是先抽出类y，再在类中抽出数据x，但在计算p(x|y)时引入了属性独立的假设。
- 判别模型是对不同类数据之间的差别进行建模，只要找到两者的区别就可以了，所以求解的是条件分布。逻辑回归就是判别模型，它计算的实际就是p(y|x)，根据训练数据得出y取不同值时条件概率的差异。

**总结：**
- 不同的学习思路对应假设空间中不同的建模方式与学习方法；
- 参数模型和非参数模型的区别体现的是全局普适性和局部适用性的区别；
- 数据模型和算法模型的区别体现的是可解释性和精确性的区别；
- 生成模型和判别模型的区别体现的是联合分布和条件分布的区别。

### 06 | 模型的设计准则
机器学习需要根据问题特点和已有数据确定具有最强解释性或预测力的模型，其过程也可以划分为类似于“学习 - 练习 - 考试”这样的三个阶段，每个阶段的目标和使用的资源可以归纳如下：
- 模型拟合（model fitting）：利用训练数据集（training set）对模型的普通参数进行拟合；
- 模型选择（model selection）：利用验证数据集（validation set）对模型的超参数进行调整，筛选出性能最好的模型；
- 模型评价（model assessment）：利用测试数据集（test set）来估计筛选出的模型在未知数据上的真实性能。

**总结：**
- 无免费午餐定理说明模型的选取要以问题的特点为根据；
- 奥卡姆剃刀说明在性能相同的情况下，应该选取更加简单的模型；
- 过于简单的模型会导致欠拟合，过于复杂的模型会导致过拟合；
- 从误差分解的角度看，欠拟合模型的偏差较大，过拟合模型的方差较大。

### 07 | 模型的验证方法
想要充分利用有限的数据，必须在训练集和验证集的划分方式，或者说验证数据的抽取方式上做些门道。最简单直接的方法就是随机采样出一部分数据作为训练集，再采样出另一部分作为验证集，这种方法就是**留出法**（hold-out）。如果机器学习过程不使用验证步骤，那么这种划分方式就相当于拿出大部分数据做训练，剩下的全部留做测试，这也是“留出”这个名称的含义。

将留出法的思想稍做推广，就可以得到常用的$k$ **折交叉验证法**（$k$-fold cross validation）。$k$ 折交叉验证将原始数据集随机划分为 $k$ 个相同大小的子集，并进行 $k$ 轮验证。每一轮验证都选择一个子集作为验证集，而将剩余的 $k-1$ 个子样本用作训练集。由于每一轮中选择的验证集都互不相同，每一轮验证得到的结果也是不同的，$k$ 个结果的均值就是对泛化性能的最终估计值。

除了 $k$ 折交叉验证之外，另一种模型验证的方法是**自助采样**（bootstrap）。在学习概率论时你肯定计算过这样的问题：一个袋子里有红球若干白球若干，从中抽出一个球查看颜色后放回或不放回，再次抽出一个红球 / 白球的概率是多少。前面提到的 $k$ 折交叉验证执行的就是典型的不放回的重采样，在同一轮验证中某个样本要么出现在训练集，要么出现在验证集，两者必居其一。相比之下，`自助采样执行的则是有放回的重采样`。如果使用自助采样生成训练集的话，需要每次随机从原始数据集中随机抽取一个样本并拷贝到训练集中，将这个样本放回到原始数据集，再重复以上的步骤。这种放回重采样的方式会导致某些数据可能在同一轮验证中多次出现在训练集内，而另一些数据可能从头到尾都没有参与到模型的训练当中。在每一轮次的自助采样中，没有被采到的样本会作为测试数据使用。

模型验证是模型原型设计的最后完善。一旦完成了模型验证，模型就不能再做调整了。这就像对陶土模型做出最后的修饰定型，至于入窑烧制的效果如何就完全听天由命，出来的成品品相不佳就只能狠心摔碎。同样的道理，即使验证之后的模型在测试集上的表现再差，也只能打掉牙往肚子里咽。若非要调整不可，就只能重启炉灶了。

**总结：**
- 模型验证的作用是选择最佳模型并确定其性能；
- 对数据的重采样可以直接实现对样本外误差，也就是泛化误差的估计；
- $k$ 折交叉验证是无放回的重采样方法；
- 自助采样是有放回的重采样方法。

### 08 | 模型的评估指标
在混淆矩阵中，所有测试样例被分为真正例（true positive, TP）、假正例（false positive, FP）、假反例（false negative, FN）、真反例（true negative, TN）四大类。真正例和真反例容易理解，假正例指的是样例本身是反例而预测结果是正例，也就是假阳性；假反例指的是样例本身是正例而预测结果是反例，也就是假阴性。这样的分类能够对机器学习模型的性能做出更加精细的刻画，`准确率（precision）`和`召回率（recall）`就是两个具体的刻画指标。

准确率 $P$ 也叫正例预测值（positive predictive value），表示的是真正例占所有预测结果为正例的样例的比值，也就是模型预测结果的准确程度。如抓回监狱的人是不是都是真正的犯人，有没有无辜的人被抓回来的情况。

召回率 $R$ 也叫真正例率（true positive rate, TPR），表示的是真正例占所有真实情况为正例的样例的比值，也就是模型对真实正例的判断能力。如是不是把所有真正的犯人都抓回来了，外面还有没有犯人。

将查准率和查全率画在同一个平面直角坐标系内，得到的就是 **P-R 曲线**，它表示了模型可以同时达到的查准率和查全率。如果一个模型的 P-R 曲线能够完全包住另一个模型的曲线，就意味着前者全面地优于后者。可是更普遍的情况是有些模型查全性能较优，而另一些模型查准性能较优，这就需要根据任务本身的特点来加以选择了。

除了 P-R 曲线外，另一个对机器学习模型性能进行可视化的方式是**受试者工作特征曲线**（receiver operating characteristic curve），简称**ROC 曲线**。ROC 这个名字来源于曲线的原始用途：判断雷达接收到的信号到底是敌机还是干扰。在机器学习中，这样的场景就演化为所有的样例共同符合一个混合分布，这个混合分布由正例和反例各自服从的单独概率分布叠加组成。此时二分类模型的任务就是确定新来的样本究竟来源于哪个分布。数据中的随机变化在分类器中体现为阈值动态取值的随机变化，分类器的性能则取决于两个概率分布之间的分离程度。

ROC 曲线可以用来衡量习得模型的性能。模型的 ROC 曲线越靠近左上方，其性能就越好。和 P-R 曲线一样，如果一个模型的 ROC 曲线能够完全包住另一个模型的曲线，那么前者的性能就优于后者。但大多数情况下，模型之间并不存在全方位的碾压性优势，自然不会出现 ROC 曲线完全包含的情形。这时要评估不同模型性能的话，就需要 ROC 曲线下面积的概念。

**总结：**
- 在二分类任务中，模型性能度量的基本指标是精度和错误率，两者之和为 1；
- 混淆矩阵是个 $2 \times 2$ 的性能度量矩阵，其元素分别是真正例、假正例、假反例和真反例的数目；
- P-R 曲线表示的是查准率和查全率之间的关系，曲线在点 (1, 1) 上达到最优性能；
- ROC 曲线表示的是真正例率和假正例率之间的关系，曲线在点 (0, 1) 上达到最优性能。

### 09 | 实验设计
实验设计（experimental design），或者叫设计实验（designed experiment），指的是在实验之前制定详细的实验计划，确定实验目标并选择待研究的过程因子（process factor）。精心挑选的实验设计可以在给定资源的条件下使实验获得的信息量最大化，让实验结果最大程度地接近真实结果。实验设计需要人为改变一个或多个过程因子，以观察这种变化对一个或多个因变量的影响，其目的是分析获得的数据以产生有效和客观的结论。

在对筛选出的少量因子进行微调时，可以使用响应面方法（response surface methodology）来降低计算开销。微调的目的是找到最优的因子取值，在不可能对所有取值都计算出性能指标的情况下，通过插值的方法来拟合出因子和性能之间的响应面就是一种更容易操作的办法。在得到的响应面上寻找最值，找到的就是最优的因子取值。

响应面通常被设定为二次曲面，用来拟合初始曲面的数据通常取在因子的基线附近。在初始曲面上找到的因子最优值被应用到学习模型之中，得到的结果作为一个新样本被添加到初始曲面里面，然后继续对响应曲面进行拟合和优化，直到得到的最优结果没有明显的改进为止。

响应曲面其实可以看成一种替代模型。替代模型（surrogate model）是对真实模型的逼近，以数据驱动的自底向上的方法构建，目标是尽可能地模拟真实模型的行为。如果机器学习中的因子较多的话，它们之间的关系可能就是无法用解析式来描述的复杂关系，替代模型就是对这种复杂关系的拟合，就像机器学习训练模型来拟合输入特征和输出结果之间的关系那样。

**总结：**
- 实验设计的任务是观察一个或多个因子对实验结果的影响；
- 机器学习中，实验设计中的因子包括算法类型、超参数、数据集等；
- 连续实验可以用来评估多个因子对实验的影响；
- 响应面方法通过二次曲面的拟合寻找可变因子的最佳取值。

### 10 | 特征预处理
多明戈斯的观点是：数据量比算法更重要。即使算法本身并没有什么精巧的设计，但使用大量数据进行训练也能起到填鸭的效果，获得比用少量数据训练出来的聪明算法更好的性能。这也应了那句老话：数据决定了机器学习的上限，而算法只是尽可能逼近这个上限。

但多明戈斯嘴里的数据可不是硬件采集或者软件抓取的原始数据，而是经过特征工程处理之后的精修数据，在他看来，特征工程（feature engineering）才是机器学习的关键。通常来说，原始数据并不直接适用于学习，而是特征筛选、构造和生成的基础。一个好的预测模型与高效的特征提取和明确的特征表示息息相关，如果通过特征工程得到很多独立的且与所属类别相关的特征，那学习过程就变成小菜一碟。

**数据预处理：**
- 处理缺失值——数据的缺失主要包括记录的缺失和记录中某个字段信息的缺失，两者都会造成分析结果的不准确。
- 特征缩放——使用标准化/归一化消除特征的不同尺度所带来的偏差
- 处理异常值——异常值分析是检验数据是否有录入错误以及含有不合常理的数据。
- 图片数据扩充——训练数据不足
- 处理类别不平衡问题——指分类任务中存在某个或者某些类别的样本数量远多于其他类别的样本数量的情况。

**总结：**
在模型训练之前对数据特征进行预处理的一些指导性原则：
- 特征缩放可以让不同特征的取值具有相同的尺度，方法包括标准化和归一化；
- 异常点会导致数据的有偏分布，对数变换和空间标识都可以去除数据的偏度；
- $k$ 近邻方法和线性回归可以用来对特征的缺失值进行人为赋值；
- 删除不具备区分度的特征能够降低计算开销，增强可解释性。

### 11 | 基础线性回归：一元与多元
**总结：**
基于最小二乘法的线性回归模型的理解：
- 线性回归拟合的是高维空间上的输出结果在由所有属性共同定义的低维空间上的正交投影；
- 简单线性回归的统计意义可以用 $t$ 统计量和 $p$ 值等指标描述；
- 多元线性回归的统计意义可以用 $F$ 统计量描述，但回归结果可能缺乏对模型的解释能力；
- 机器学习与统计学的区别在于机器学习重于预测，统计学则重于解释。

### 12 | 正则化处理：收缩方法与边际化
正则化（regularization）是用于抑制过拟合的方法的统称，它通过动态调整估计参数的取值来降低模型的复杂度，以偏差的增加为代价来换取方差的下降。这是因为当一些参数足够小时，它们对应的属性对输出结果的贡献就会微乎其微，这在实质上去除了非相关属性的影响。

在线性回归里，最常见的正则化方式就是在损失函数（loss function）中添加正则化项（regularizer），而添加的正则化项 $R(\lambda)$ 往往是待估计参数的 $p$- 范数。将均方误差和参数的范数之和作为一个整体来进行约束优化，相当于额外添加了一重关于参数的限制条件，避免大量参数同时出现较大的取值。由于正则化的作用通常是让参数估计值的幅度下降，因此在统计学中它也被称为系数收缩方法（shrinkage method）。

**岭回归和 LASSO 的区别：**
岭回归的作用是衰减不同属性的权重，让所有属性一起向圆心收拢；LASSO 则直接将某些属性的权重降低为 0，完成的是属性过滤的任务。而弹性网络作为两者的折中，结合了不同的优点：它不会轻易地将某些属性抛弃，从而使全部信息得以保留，但对不重要的特征也会毫不手软地大幅削减其权重系数。

LASSO 将 4 个特征中 2 个的系数缩减为 0，这意味着一半的特征被淘汰掉了，其中就包括倒霉的守门员。在 LASSO 看来，对比赛做出贡献的只有中场和前锋球员，而中场的作用又远远不及前锋——这样的结果是否是对英超注重进攻的直观印象的佐证呢？

**岭回归 vs LASSO：**
当参数的数目远远大于样本的数目的高维统计问题，并且参数的选择比较简单粗暴，其中有不少参数存在相关性时，比较建议用LASSO回归来降低参数数目。这样处理后才能做矩阵求逆运算。

`LASSO回归会让很多参数的系数变成零，只保留一部分参数`，一般是保留系数最大的，系数小的因子很可能是噪音。参数取值的幅度有可能不一样，比如有的参数是-1到1，有的是-10到10，那么系数也会受影响。因此，在使用LASSO之前，需要对参数的取值幅度进行调整，这样计算出来的系数才具有可比性。

当样本数远大于参数的数目时，岭回归计算更快。如果参数数量少而精，数值都调整好，偏度、峰度、正态化、去极值等等，而且普遍适用多种场景，参数可解释，这时比较适合用岭回归。

`岭回归不会删除参数，会对参数的取值幅度进行压缩。`特征值小的特征向量会被压缩得最厉害，因此，它也要求参数取值幅度最好差不多，这样系数差不多，压缩起来才更有意义。和 LASSO 相比，岭回归保留了所有的特征，并给门将的表现赋予了接近于 0 的权重系数，以削弱它对结果的影响，其它的权重系数也和原始多元回归的结果更加接近。但 LASSO 和岭回归的均方误差都高于普通线性回归的均方误差，LASSO 的性能还要劣于岭回归的性能，这是抑制过拟合和降低误差必然的结果。

**总结：**
- 正则化的作用是抑制过拟合，通过增加偏差来降低方差，提升模型的泛化性能；
- 正则化项的作用是对解空间添加约束，在约束范围内寻找产生最小误差的系数；
- 频率视角下的正则化与贝叶斯视角下的边际化作用相同；
- 边际化对未知的参数和超参数进行积分以消除它们的影响，天然具有模型选择的功能。

### 13 | 线性降维：主成分的使用
和 LASSO 这种间接去除属性的收缩方法相对应的是维度规约。维度规约这个听起来个高大上的名称是数据挖掘中常用的术语，它有一个更接地气的同义词，就是降维（dimensionality reduction），也就是直接降低输入属性的数目来削减数据的维度。

当主成分回归中使用的主成分数目等于数据的属性数目 $p$ 时，主成分回归和岭回归的结果是一致的。可如果放弃方差最小的若干个主成分，得到的就是约化的回归结果，从而更加清晰地体现出主成分分析的思想。

主成分分析是典型的特征提取方法，它和收缩方法的本质区别在于将原始的共线性特征转化为人为生成的正交特征，从而带来了数据维度的约简和数据压缩的可能性。数字图像处理中的特征脸方法是主成分回归最典型的应用之一。

**总结：**
- 在有限的数据集下，数据维度过高会导致维数灾难；
- 降维的方法包括特征选择和特征提取；
- 主成分分析将原始的共线性特征转化为新的正交特征，从而实现特征提取；
- 概率主成分分析是因子分析的一种，是数据的生成模型。

### 14 | 非线性降维：流形学习
虽然流形这个词本身有着浓厚的学院派味道，但它的思想你却一点儿不会陌生。最著名的流形模型恐怕非瑞士卷（Swiss roll）莫属。如图所示的瑞士卷是常见的糕点，只是它的名字未必像它的形状一样广为人知。瑞士卷实际上是一张卷起来的薄蛋糕片，虽然卷曲的操作将它从二维形状升级成了三维形状，但这个多出来的空间维度并没有产生关于原始结构的新信息，所以瑞士卷实际上就是嵌入三维空间的二维流形。

在机器学习中，流形（manifold）指的是嵌入在高维数据空间中的低维子空间，它的维数是低维数据变化的自由度（degree of freedom of variability），也叫作固有维度（intrinsic dimensionality）。流形学习（manifold learning）正是通过挖掘数据的内在结构实现向固有维度的降维，从而找到与高维原数据对应的低维嵌入流形。

和主成分分析相比，流形可以是线性的，但更多是非线性的。正因如此，流形学习通常被视为非线性降维方法的代表。它不仅能够缓解维数灾难的影响，还具有比线性降维方法更强的特征表达能力。除了非线性外，流形学习的方法一般还是非参数的，这使流形能够更加自由地表示数据的固有维度和聚类特性，但也让它对噪声更加敏感。

要将数据从高维空间映射到低维流形上，首先要确定低维流形的结构，其次要确定高维空间到低维流形的映射关系。可在实际问题中，不管是流形结构还是流形维数都不是已知的，因此有必要做出一些先验假设以缩小问题的解空间。当关于流形的假设聚焦在数据的几何性质上时，就可以得到多维缩放（multiple dimensional scaling）算法。

既然都能实现数据的降维，那么以主成分分析为代表的线性方法和以流形学习为代表的非线性方法各自的优缺点在哪里呢？一言以蔽之，线性方法揭示数据的规律，非线性方法则揭示数据的结构。

主成分分析可以去除属性之间的共线性，通过特征提取揭示数据差异的本质来源，这为数据的分类提供了翔实的依据；而流形学习虽然不能解释非线性变化的意义，却可以挖掘出高维数据的隐藏结构并在二维或三维空间中直观显示，是数据可视化的利器，而不同的隐藏结构又可以作为特征识别的参考。

**总结：**
- 流形学习是非线性的降维方法，目的在于找到与高维数据对应的低维嵌入流形；
- 等度量映射是基于全局信息的流形学习方法，通过测地距离和欧氏距离的等效性计算流形；
- 局部线性嵌入是基于局部信息的流形学习方法，通过局部线性系数的不变性计算流形；
- $t$ 分布随机近邻嵌入将欧氏距离映射为相似性，利用相似性的保持计算流形。

### 15 | 从回归到分类：联系函数与降维
**总结：**
使用线性模型解决分类问题的方法：
- 在解决分类问题时，线性模型的回归值可以通过联系函数转化为分类结果；
- 线性判别分析假定数据来自均值不同但方差相同的正态分布，通过最大化类间方差与类内方差的比值计算线性边界；
- 逻辑回归计算的是不同类别的概率决策边界，输出的是给定数据属于不同类别的后验概率；
- 基于线性模型的分类方法计算出的决策边界是输入属性的线性函数。

### 16 | 建模非正态分布：广义线性模型
误差的正态分布意味着因变量既可以增加也减少，其增加或者减少的范围虽然不存在上限，却以较大的概率出现在一个较小的区间内。如果按照前文的方式改造狭义线性模型的话，噪声的正态性质就不能得以保持，简洁明晰的解析解也会不再适用。因此，要拓展线性模型的应用范围，新的数学工具不可或缺。

广义线性模型（generalized linear model）就是这样的数学工具。在广义线性模型中，因变量可以满足任意形式的概率分布，它与自变量的线性组合之间的关系由联系函数定义。逻辑回归就是广义线性模型的一个实例，它的因变量是二进制的输出，联系函数则是对数几率函数。这个实例体现出了在一般意义上，广义线性模型要满足一些共性的条件。

**总结：**
广义线性模型的概念与原理，它克服了狭义线性模型的一些限制，拓展了线性模型的应用范围：
- 广义线性模型从模型解释性和变量分布特性上对普通线性模型做了推广；
- 广义线性模型假定因变量服从指数分布族中的概率分布，这代表了模型中的随机成分；
- 广义线性模型中的自变量和因变量依然由线性系数决定，这代表了模型中的系统成分；
- 联系函数建立系统成分和随机成分的关系，将指数分布的自然参数表示为自变量的线性组合。

### 17 | 几何角度看分类：支持向量机
俗话说得好：“支持向量机有三宝，间隔对偶核技巧”。一提到支持向量机，大部分人的第一反应都是核技巧。可核技巧诞生于 1995 年，而支持向量机早在 30 年前就已经面世。支持向量机（support vector machine）是基于几何意义的非概率线性二分类器，所谓的核技巧（kernel trick）只是支持向量机的一个拓展，通过维度的升高将决策边界从线性推广为非线性。所以对于支持向量机的基本原则的理解与核技巧无关，而是关乎决策边界的生成方式。

**总结：**
- 支持向量机是基于线性判别式几何意义的分类算法；
- 支持向量机通过间隔最大化来定义最优的决策边界；
- 支持向量机通过对偶问题来求解最优的决策边界；
- 支持向量机的目标是让结构风险最小化。

### 18 | 从全局到局部：核技巧
**总结：**
- 支持向量机在求解最优边界时需要利用对偶性，将原问题转化为对偶问题求解；
- 在思想上，核方法将高维空间上的线性边界转化成低维空间上的非线性边界；
- 在运算上，核技巧能在低维空间中直接计算高维空间中的内积；
- 核函数具有局部化的特点，是从全局模型到局部模型的过渡手段。

### 19 | 非参数化的局部模型：K近邻
$k$ 均值的分类结果实质上是近邻区域内（就是上图中的圆圈）多个训练实例的平均，越大的 $k$ 值意味着近邻区域包含的点数越多，平均化的程度就越高，对训练实例中噪声的平滑效果也就越好，相应的模型复杂度就越低。$k$ 的一个极端取值是直接等于训练集的容量，这相当于所有数据共同定义了同一个局部结构，这时的 $k$ 近邻就退化成稳定的全局模型了。

反过来，越小的 $k$ 值意味着近邻区域越狭窄，平均化的程度也就越低。这时的分类结果只由离未知数据点最近的少量训练实例决定，因而更容易受到这些实例中噪声的影响，也会表现出更强的过拟合倾向。当 $k$ 等于 1 时，未知数据的类别只取决于离它最近的训练实例。

除了超参数 $k$ 之外，$k$ 近邻算法的另一个变量是对距离的定义方式，也就是如何衡量哪些点才是“近邻”的标准。最常用的距离度量无疑是欧氏距离，可除此之外，闵可夫斯基距离（Minkowski distance）、曼哈顿距离（Manhattan distance）和马氏距离（Mahalanobis distance）也可以应用在 $k$ 近邻算法中，不同的距离代表的是对相似性的不同理解，在不同意义的相似性下，分类结果往往也会有所区别。

**总结：**
- 基于实例的学习方法学的不是明确的泛化模型，而是样本之间的关系；
- $k$ 近邻算法是非参数的局部化模型，具有无需训练的优点，但分类新实例的计算复杂度较高；
- $k$ 近邻算法的性能取决于超参数 $k$ 的取值和距离的定义方式；
- 核方法和近邻算法都可以用于数据的概率密度估计。

### 20 | 基于距离的学习：聚类与度量学习
聚类分析（cluster analysis）实际上是一种分组方式，它使每一组中的组内对象的相似度都高于组间对象的相似度，分出来的每个组都是一个簇（cluster）。由于相似度是聚类的依据，作为相似度主要度量方式之一的距离就在聚类中发挥着重要作用。

**总结：**
- 聚类分析是一类描述模型，它将数据按照相似度分成不同的簇；
- $k$ 均值算法根据距离来判定数据的聚类；
- 从概率角度看，$k$ 均值算法是高斯混合模型的一种特例；
- 度量学习的任务是构造出适合于给定问题的距离度量或相似度的度量。

### 21 | 基函数扩展：属性的非线性化
**总结：**
通过基函数扩展实现非线性模型的方法，包含以下四个要点：
- 基扩展将线性回归中的自变量替换为非线性的函数，使模型能够描述非线性关系；
- 多项式回归将回归结果表示为属性的多项式之和；
- 样条方法将回归结果表示为若干非线性函数的组合，可以分为回归样条和平滑样条；
- 广义可加模型是对多元线性回归的基扩展。

### 22 | 自适应的基函数：神经网络
**总结：**
- 神经网络是一类非线性模型，利用非线性的激活函数对输入的线性组合进行分类；
- 神经网络可以通过误差反向传播自适应地调整网络结构中的参数；
- 神经网络中隐藏层的作用是构造出新的导出特征；
- 用贝叶斯方法分析神经网络时，需要使用近似方法来应对非线性导致的计算问题。

### 23 | 层次化的神经网络：深度学习
深度神经网络是具有多个隐藏层的神经网络，也可以说是浅层神经网络的层次化（hierarchical）组合，其背后是多级的思想。如果把层次化的深度网络压扁成一个平面，得到的就是全连接的单隐藏层神经网络；反过来，深度网络也可以看成是对满足通用逼近定理的单层网络的正则化，通过削减多余的连接来提升网络的泛化性能。

**层次化**（hierarchicalization）其实是解决问题的一种固有思路，大到政府架构小到快递配送都能看到层次化的身影。层次化的机器学习是将一个复杂的问题分解成若干个简单的问题，再在不同的层面上对这些简单问题进行表示和学习。

从功能上看，深度神经网络通过多个隐藏层的级联实现对输入特征连续不断的非线性处理，提取和变换出了新的特征，每个层次都能够将它的输入数据转换成更加抽象一些的复合表示，这就相当于通过结构的层次化实现抽象特征的层次化。

除了层次化之外，深度学习的另一个主要特点是**分布式**，由本吉奥在深度学习的开山文献《人工智能中的深度结构学习》（Learning Deep Architectures for AI）中提出。

维度灾难：在构造局部模型时，数据维度的增加会让低维空间中数据点的近邻不再保持，新来的数据就可能找不到任何作为参考的近邻点；而在构造全局模型时，数据维度的增加又会增加模型中参数的数量，使不同自变量对因变量的贡献程度变得难以衡量，导致多元线性回归中的“罗生门”现象。

同是处理高维数据，深度学习采用了分布式表示（distributed representation），将作为整体的高维特征打散成若干个低维特征的组合。

**总结：**
- 深度神经网络是具有层次化结构的多层神经网络；
- 深度神经网络采用分布式表示，提升了网络结构的表达能力和学习能力；
- 深度神经网络是一组堆叠起来的广义线性模型；
- 深度学习能够找到高维数据所对应的低维流形。

### 24 | 深度编解码：表示学习
自编码器（autoencoder）属于生成模型，它的作用是以无监督的学习方式学到数据集的稀疏表示，从而给数据降维。显然，它和前面介绍过的主成分分析殊途同归。可以证明，如果自编码器只有一个线性隐藏层，同时使用均方误差作为损失函数，那么 $k$ 个隐藏神经元的权重系数就代表了输入数据的 $k$ 个主成分。

**总结：**
- 编解码结构可以重构数据的表示方式，提取出高层次的特征；
- 自编码器将编码器和解码器集成到同一个深度网络中，是一种无监督的生成模型；
- 卷积神经网络和循环神经网络都可以用来构造编解码结构；
- 表示学习也叫特征学习，是让机器自动提取数据特征的技术。

### 25 | 基于特征的区域划分：树模型
无论是回归树还是分类树，在生成时都遵循相同的流程，就是先划分特征空间，再对每个特征空间去拟合。两者的区别主要在于选择划分特征时采用的指标不同。和线性回归相比，决策树更加符合人类做出决策、尤其是像医学诊断这类决策的思维流程，它的描述性还要更好一些。但是决策树对加性关系的表达能力不强，如果因变量真的是自变量的线性组合的话，使用决策树恐怕就要弄巧成拙了。

决策树一个主要的缺点是对数据点异常敏感，训练数据集一点不起眼的变动就足以生成一棵完全不同的决策树，而数据集中的异常点也会对决策树结果造成未知的影响。此外，在处理回归任务时，决策树得到的是不连续的结果。这样看来，回归样条就可以视为决策树的一个优化。

广义来看，决策树可以视为对基本线性模型的层次化集成，这里的基本模型就是数据在每个划分区域上的回归或分类规则，这些规则一般是线性的。决策树的作用是将这些固定的局部线性规则进行拼接式的组合，从而生成整体意义上的非线性模型。后面我们将发现，看似简单的集成策略却能在机器学习中发挥出出人意料的优异性能。

**总结：**
- 决策树是局部化的非参数模型；
- 决策树生成算法先将特征空间划分成若干区域，再在每个区域上拟合输出；
- 决策树能够更加灵活地刻画不同属性之间的相互作用；
- 决策树可以看成最简单的集成模型。

### 26 | 集成化处理：Boosting与Bagging
boosting和bagging都是集成学习（ensemble learning）领域的基本算法，boosting和bagging使用的多个分类器的类型是一致的。

**Bagging**：
bagging也叫自助汇聚法（bootstrap aggregating），比如原数据集中有N个样本，我们每次从原数据集中有放回的抽取，抽取N次，就得到了一个新的有N个样本的数据集，然后我们抽取S个N次，就得到了S个有N个样本的新数据集，然后拿这S个数据集去训练S个分类器，之后应用这S个分类器进行分类，选择分类器投票最多的类别作为最后的分类结果。

**boosting与bagging的区别：**
`bagging通过有放回的抽取得到了S个数据集，而boosting用的始终是原数据集，但是样本的权重会发生改变。`
boosting对分类器的训练是串行的，每个新分类器的训练都会受到上一个分类器分类结果的影响。
bagging里面各个分类器的权重是相等的，但是boosting不是，每个分类器的权重代表的是其对应分类器在上一轮分类中的成功度。

**AdaBoosts算法:**
> AdaBoost（adaptive boosting）是元算法，通过组合多个弱分类器来构建一个强分类器。我们为训练数据中的每一个样本都赋予其一个权重，这些权重构成了向量D，一开始，这些权重都初始化成相等值，然后每次添加一个弱分类器对样本进行分类，从第二次分类开始，将上一次分错的样本的权重提高，分对的样本权重降低，持续迭代。此外，对于每个弱分类器而言，每个分类器也有自己的权重，取决于它分类的加权错误率，加权错误率越低，则这个分类器的权重值α越高，最后综合多个弱分类器的分类结果和其对应的权重α得到预测结果，AdaBoost是最好的监督学习分类方法之一。


**总结：**
集成学习的基本原理，以及典型的集成学习方法，包含以下四个要点：
- 集成学习可以将多个弱学习器组合成强学习器，是模型的融合方法；
- 提升方法通过重新分配数据的权重来改善弱学习器，可以提升模型的偏差性能；
- 装袋方法通过重新采样数据来改善弱学习器，可以提升模型的方差性能；
- 堆叠方法通过重新构造输出来改善弱学习器，可以看成广义的模型选择。

### 27 | 万能模型：梯度提升与随机森林
上一篇文章中我和你分享了提升法和装袋法这两种典型的集成方法，它们都可以用在决策树模型上，对多棵不同的树进行组合。然而直接使用这两种集成方法只是初级的策略，将它们的强化版用在决策树上可以得到更加强大的万能模型，也就是梯度提升决策树和随机森林。

以决策树作为基学习器，使用梯度提升方法进行集成，得到的就是梯度提升决策树（gradient boosting decision tree, GBDT）。在每一轮的提升过程中，GBDT 都会使用决策树来拟合计算出负梯度，因此整个模型就是一大堆决策树的组合。

随机森林（ramdom forest）由若干个随机树（random tree）模型组成，每一棵单独的随机树都采用自助采样作为数据重采样的手段，但只会随机选择少量的特征用于生成树结构，这样生成的随机树也无需进行剪枝的处理。

**总结：**
梯度提升决策树和随机森林这两种万能模型，包含以下四个要点：
- 梯度提升决策树和随机森林都是在各类问题上表现优异的通用模型；
- 梯度提升决策树是提升方法的推广，利用上一轮次的梯度信息构造决策树；
- 随机森林是装袋方法的推广，利用属性随机化和数据随机化构造决策树；
- 误差 - 分歧分解解释了集成学习强调基学习器多样性的原因。

### 28 | 最简单的概率图：朴素贝叶斯
**总结：**
- 朴素贝叶斯是最简单的概率图模型，具有发散的星型结构；
- 朴素贝叶斯能够计算属性和类别的联合分布，因而属于生成模型；
- 共轭先验可以保证先验分布和后验分布具有相同的形式和不同的参数；
- 拉普拉斯平滑的作用是给类别设定均匀分布的共轭先验。

### 30 | 无向图模型：马尔可夫随机场
**总结：**
- 马尔可夫随机场是无向图，可以用于建模变量之间的相互作用；
- 马尔可夫随机场与可以进行因子分解的吉布斯分布等价；
- 马尔可夫随机场中的条件独立性可以分为全局性、局部性和成对性；
- 马尔可夫随机场和贝叶斯网络可以相互转化。

### 31 | 建模连续分布：高斯网络
**总结：**
- 高斯网络采用高斯线性模型建模连续变量，其数字特征为均值向量和协方差矩阵；
- 高斯贝叶斯网络利用多元高斯分布生成独立图，利用信息矩阵计算网络中的条件概率；
- 高斯马尔可夫随机场具有成对马尔可夫性，通过高斯分布可以确定结点势和边势；
- 混合网络是同时具有离散型结点和连续型结点的概率图模型。

### 32 | 从有限到无限：高斯过程
**总结：**
- 高斯过程由无穷多个随机变量组成，定义的是函数的先验分布；
- 函数空间上的高斯过程是核技巧在概率模型中的应用，通过定义因变量之间的相关性计算输出；
- 参数空间上的高斯过程是在高维空间中进行贝叶斯的回归分析；
- 高斯过程可以通过等价核、似然概率和高斯先验与其他模型联系起来。

### 33 | 序列化建模：隐马尔可夫模型
**总结：**
- 隐马尔可夫模型由隐藏的状态序列和可见的观测序列构成，能够对时序依赖关系建模；
- 隐马尔可夫模型的定量描述包括初始状态向量、状态转移矩阵和观测矩阵三部分；
- 作为生成模型，隐马尔可夫可以视为混合模型的推广；
- 隐马尔可夫模型的判别方法对应是条件随机场。

### 34 | 连续序列化模型：线性动态系统
**总结：**
- 线性动态系统是具有连续状态变量的隐马尔可夫模型，所有条件概率都是线性高斯分布；
- 线性动态系统的求解是根据先验置信状态和观测结果来更新系统的置信状态；
- 卡尔曼滤波器可以对线性动态系统进行精确求解；
- 当系统具有非线性和非高斯特性时，可以通过扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波等方法求解。

### 35 | 精确推断：变量消除及其拓展
**总结：**
- 推断是利用图结构表示的概率分布计算查询变量的概率，可以分为精确推断和近似推断；
- 变量消除通过对非查询变量的边际化处理实现精确推断，具体步骤包括因子乘积和变量求和；
- 置信传播通过消息传递实现精确推断，具有较高的计算效率；
- 将图模型改造成团树结构可以保证置信传播算法的收敛性。

### 36 | 确定近似推断：变分贝叶斯
**总结：**
- 变分贝叶斯推断是基于确定性近似的推断方法；
- 变分贝叶斯用简单的近似分布来拟合真实的后验分布，并利用平均场分解简化对变分下界的优化；
- 变分消息传播可以在贝叶斯网络上实现变分推断；
- 变分贝叶斯和 EM 算法都是对隐变量的处理，可以从统一的角度分析。

### 37 | 随机近似推断：MCMC
**总结：**
- MCMC 是基于随机性近似的推断方法；
- MCMC 利用基于蒙特卡洛方法的随机采样将任意的初始分布转化为马尔可夫链的稳态分布；
- MCMC 的关键问题是找到和目标稳态分布匹配的转移矩阵；
- MCMC 的典型方法包括一维的 MH 算法和多维的吉布斯采样。

### 38 | 完备数据下的参数学习：有向图与无向图
**总结：**
- 参数学习的任务是在已知模型结构的前提下估计其参数，可以看成是模型的训练；
- 贝叶斯网络的参数学习可以由整体分解为局部，在局部上应用最大似然估计或者最大后验估计；
- 马尔可夫随机场的参数学习不能分解，也不存在解析解，可以使用通用的迭代比例拟合方法找到全局最优解；
- 马尔可夫随机场的参数学习可以通过近似推理和目标函数替换加以简化。

### 39 | 隐变量下的参数学习：EM方法与混合模型
期望最大化算法（expectation-maximization algorithm, EM）是用于计算最大似然估计的迭代方法，其中的期望步骤（expectation step）利用当前的参数来生成关于隐变量概率的期望函数，最大化步骤（maximization step）则寻找让期望函数最大的一组参数，并将这组参数应用到下一轮的期望步骤中。如此循环往复，算法就可以估计出隐变量的概率分布。

**总结：**
- 期望最大化算法通过迭代来求解令观测结果似然概率最大化的未知参数；
- 期望步骤计算完备数据的似然概率关于隐变量的数学期望；
- 最大化步骤通过最大化期望步骤的结果来计算新的参数估计值；
- 期望最大化算法主要用于高斯混合模型等含有隐变量的概率图模型的学习。

### 40 | 结构学习：基于约束与基于评分
**总结：**
- 结构学习的任务是找到与数据匹配度最高的网络结构，需要同时确定图模型的结构和参数；
- 基于约束的结构学习通过条件独立性的约束确定贝叶斯网络的结构，需要先后确定边的存在性和方向；
- 基于评分的结构学习通过数据和结构的匹配度确定贝叶斯网络的结构，包括选择评分函数和搜索最优结构两个步骤；
- 对不完备数据实施结构学习可以使用结构 EM 算法。